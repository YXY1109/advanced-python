本段文本主要讲解了如何使用Python编写一个异步的网页爬虫，并将爬取到的数据存入MySQL数据库。具体步骤如下：

1. 使用`asyncio`和`aiohttp`库来创建异步任务，返回网页的文本内容。过程中可能遇到异常，建议使用`try...except`语句处理。
2. 在主程序中，初始化一个连接池，连接MySQL数据库，注意设置字符集为`utf8`，并且设置`autocommit=True`，避免数据插入问题。
3. 使用列表`waiting_urls`和集合`signed_urls`分别存储待抓取和已抓取的URL，这里建议使用布隆过滤器来去重，提高效率。
4. 从一个起始URL（`start_url`）获取页面，解析出所有待抓取的链接，并将其加入到`waiting_urls`中。
5. 定义一个消费者(`consumer`)协程，从`waiting_urls`中不断获取URL，启动异步任务进行抓取，并将结果处理后保存到数据库中。
6. 在抓取文章详情页面时，使用`pyquery`提取页面中的URL和正文内容，对正文内容进行保存到MySQL数据库的操作。

整个过程强调了异步IO的重要性，并且通过异步爬虫提高了爬取效率。文本还提到了一些实现上的注意事项，如处理同步异步混用的问题，以及使用Python和相关库的具体细节。